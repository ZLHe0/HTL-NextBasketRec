[[07/31/2023 01:45:45 AM]] 
new run with parameters:
{'batch_size': 128,
 'checkpoint_dir': './checkpoints_nn',
 'early_stopping_steps': 300,
 'enable_parameter_averaging': False,
 'grad_clip': 5,
 'hidden_units': 64,
 'keep_prob_scalar': 1.0,
 'learning_rate': 0.005,
 'log_dir': './logs_nn',
 'log_interval': 20,
 'loss_averaging_window': 100,
 'min_steps_to_checkpoint': 100,
 'num_restarts': 0,
 'num_training_steps': 2000,
 'num_validation_batches': 2,
 'optimizer': 'adam',
 'prediction_dir': './predictions_nn',
 'reader': <__main__.DataReader object at 0x2b752b7be198>,
 'regularization_constant': 0.0,
 'warm_start_init_step': 0}
[[07/31/2023 01:46:16 AM]] all parameters:
[[07/31/2023 01:46:16 AM]] [('dense1/weights:0', [51, 64]),
 ('dense1/biases:0', [64]),
 ('dense2/weights:0', [115, 1]),
 ('dense2/biases:0', [1]),
 ('Variable:0', []),
 ('Variable_1:0', []),
 ('beta1_power:0', []),
 ('beta2_power:0', []),
 ('dense1/weights/Adam:0', [51, 64]),
 ('dense1/weights/Adam_1:0', [51, 64]),
 ('dense1/biases/Adam:0', [64]),
 ('dense1/biases/Adam_1:0', [64]),
 ('dense2/weights/Adam:0', [115, 1]),
 ('dense2/weights/Adam_1:0', [115, 1]),
 ('dense2/biases/Adam:0', [1]),
 ('dense2/biases/Adam_1:0', [1])]
[[07/31/2023 01:46:16 AM]] trainable parameters:
[[07/31/2023 01:46:16 AM]] [('dense1/weights:0', [51, 64]),
 ('dense1/biases:0', [64]),
 ('dense2/weights:0', [115, 1]),
 ('dense2/biases:0', [1])]
[[07/31/2023 01:46:16 AM]] trainable parameter count:
[[07/31/2023 01:46:16 AM]] 3444
[[07/31/2023 01:46:16 AM]] [[step        0]]     [[train]]     loss: 0.6960032        [[val]]     loss: 0.69063264       
[[07/31/2023 01:46:16 AM]] [[step       20]]     [[train]]     loss: 0.45518322       [[val]]     loss: 0.44806175       
[[07/31/2023 01:46:16 AM]] [[step       40]]     [[train]]     loss: 0.39234929       [[val]]     loss: 0.40057873       
[[07/31/2023 01:46:16 AM]] [[step       60]]     [[train]]     loss: 0.36262161       [[val]]     loss: 0.37407608       
[[07/31/2023 01:46:16 AM]] [[step       80]]     [[train]]     loss: 0.35596816       [[val]]     loss: 0.36113291       
[[07/31/2023 01:46:16 AM]] [[step      100]]     [[train]]     loss: 0.3483411        [[val]]     loss: 0.35282243       
[[07/31/2023 01:46:16 AM]] [[step      120]]     [[train]]     loss: 0.32424924       [[val]]     loss: 0.32854361       
[[07/31/2023 01:46:16 AM]] saving model to ./checkpoints_nn/model
[[07/31/2023 01:46:17 AM]] [[step      140]]     [[train]]     loss: 0.32249309       [[val]]     loss: 0.32706538       
[[07/31/2023 01:46:17 AM]] saving model to ./checkpoints_nn/model
[[07/31/2023 01:46:17 AM]] [[step      160]]     [[train]]     loss: 0.32448913       [[val]]     loss: 0.32478035       
[[07/31/2023 01:46:17 AM]] saving model to ./checkpoints_nn/model
[[07/31/2023 01:46:17 AM]] [[step      180]]     [[train]]     loss: 0.3159606        [[val]]     loss: 0.32596948       
[[07/31/2023 01:46:17 AM]] [[step      200]]     [[train]]     loss: 0.31413133       [[val]]     loss: 0.32361125       
[[07/31/2023 01:46:17 AM]] saving model to ./checkpoints_nn/model
[[07/31/2023 01:46:18 AM]] [[step      220]]     [[train]]     loss: 0.31213913       [[val]]     loss: 0.32209144       
[[07/31/2023 01:46:18 AM]] saving model to ./checkpoints_nn/model
[[07/31/2023 01:46:18 AM]] [[step      240]]     [[train]]     loss: 0.3097111        [[val]]     loss: 0.31977808       
[[07/31/2023 01:46:18 AM]] saving model to ./checkpoints_nn/model
[[07/31/2023 01:46:18 AM]] [[step      260]]     [[train]]     loss: 0.31049046       [[val]]     loss: 0.32526632       
[[07/31/2023 01:46:18 AM]] [[step      280]]     [[train]]     loss: 0.31513381       [[val]]     loss: 0.32064064       
[[07/31/2023 01:46:18 AM]] [[step      300]]     [[train]]     loss: 0.31032067       [[val]]     loss: 0.32174271       
[[07/31/2023 01:46:19 AM]] [[step      320]]     [[train]]     loss: 0.310878         [[val]]     loss: 0.32407679       
[[07/31/2023 01:46:19 AM]] [[step      340]]     [[train]]     loss: 0.31062657       [[val]]     loss: 0.32188498       
[[07/31/2023 01:46:19 AM]] [[step      360]]     [[train]]     loss: 0.31014687       [[val]]     loss: 0.31599841       
[[07/31/2023 01:46:19 AM]] saving model to ./checkpoints_nn/model
[[07/31/2023 01:46:19 AM]] [[step      380]]     [[train]]     loss: 0.30754043       [[val]]     loss: 0.32028381       
[[07/31/2023 01:46:19 AM]] [[step      400]]     [[train]]     loss: 0.30764859       [[val]]     loss: 0.32043716       
[[07/31/2023 01:46:19 AM]] [[step      420]]     [[train]]     loss: 0.30672909       [[val]]     loss: 0.31801267       
[[07/31/2023 01:46:19 AM]] [[step      440]]     [[train]]     loss: 0.31028163       [[val]]     loss: 0.3190049        
[[07/31/2023 01:46:19 AM]] [[step      460]]     [[train]]     loss: 0.31049207       [[val]]     loss: 0.32360834       
[[07/31/2023 01:46:20 AM]] [[step      480]]     [[train]]     loss: 0.31206907       [[val]]     loss: 0.31997629       
[[07/31/2023 01:46:20 AM]] [[step      500]]     [[train]]     loss: 0.30986461       [[val]]     loss: 0.31911242       
[[07/31/2023 01:46:20 AM]] [[step      520]]     [[train]]     loss: 0.30837321       [[val]]     loss: 0.31912992       
[[07/31/2023 01:46:20 AM]] [[step      540]]     [[train]]     loss: 0.30724555       [[val]]     loss: 0.31806195       
[[07/31/2023 01:46:20 AM]] [[step      560]]     [[train]]     loss: 0.30367964       [[val]]     loss: 0.31417599       
[[07/31/2023 01:46:20 AM]] saving model to ./checkpoints_nn/model
[[07/31/2023 01:46:20 AM]] [[step      580]]     [[train]]     loss: 0.30454126       [[val]]     loss: 0.31954363       
[[07/31/2023 01:46:20 AM]] [[step      600]]     [[train]]     loss: 0.30876081       [[val]]     loss: 0.31596524       
[[07/31/2023 01:46:20 AM]] [[step      620]]     [[train]]     loss: 0.30478455       [[val]]     loss: 0.32096637       
[[07/31/2023 01:46:20 AM]] [[step      640]]     [[train]]     loss: 0.30076084       [[val]]     loss: 0.32106601       
[[07/31/2023 01:46:20 AM]] [[step      660]]     [[train]]     loss: 0.30558155       [[val]]     loss: 0.32400787       
[[07/31/2023 01:46:21 AM]] [[step      680]]     [[train]]     loss: 0.30347909       [[val]]     loss: 0.32045615       
[[07/31/2023 01:46:21 AM]] [[step      700]]     [[train]]     loss: 0.30414455       [[val]]     loss: 0.32364503       
[[07/31/2023 01:46:21 AM]] [[step      720]]     [[train]]     loss: 0.31321119       [[val]]     loss: 0.32004717       
[[07/31/2023 01:46:21 AM]] [[step      740]]     [[train]]     loss: 0.31891517       [[val]]     loss: 0.31907581       
[[07/31/2023 01:46:21 AM]] [[step      760]]     [[train]]     loss: 0.315886         [[val]]     loss: 0.32033255       
[[07/31/2023 01:46:21 AM]] [[step      780]]     [[train]]     loss: 0.31627891       [[val]]     loss: 0.31924162       
[[07/31/2023 01:46:21 AM]] [[step      800]]     [[train]]     loss: 0.31270046       [[val]]     loss: 0.31938388       
[[07/31/2023 01:46:21 AM]] [[step      820]]     [[train]]     loss: 0.3070173        [[val]]     loss: 0.31945442       
[[07/31/2023 01:46:21 AM]] [[step      840]]     [[train]]     loss: 0.30009307       [[val]]     loss: 0.31917107       
[[07/31/2023 01:46:21 AM]] [[step      860]]     [[train]]     loss: 0.30630519       [[val]]     loss: 0.31481412       
[[07/31/2023 01:46:21 AM]] [[step      880]]     [[train]]     loss: 0.30900081       [[val]]     loss: 0.31777246       
[[07/31/2023 01:46:21 AM]] best validation loss of 0.3141759915649891 at training step 560
[[07/31/2023 01:46:21 AM]] early stopping - ending training.
[[07/31/2023 01:46:21 AM]] restoring model parameters from ./checkpoints_nn/model-560
[[07/31/2023 01:46:23 AM]] saving order_ids with shape (252278,) to ./predictions_nn/order_ids.npy
[[07/31/2023 01:46:23 AM]] saving product_ids with shape (252278,) to ./predictions_nn/product_ids.npy
[[07/31/2023 01:46:23 AM]] saving predictions with shape (252278,) to ./predictions_nn/predictions.npy
[[07/31/2023 01:46:23 AM]] saving labels with shape (252278,) to ./predictions_nn/labels.npy
