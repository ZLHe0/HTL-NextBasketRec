[[07/29/2023 06:09:59 PM]] 
new run with parameters:
{'batch_size': 128,
 'checkpoint_dir': './checkpoints_nn',
 'early_stopping_steps': 300,
 'enable_parameter_averaging': False,
 'grad_clip': 5,
 'hidden_units': 64,
 'keep_prob_scalar': 1.0,
 'learning_rate': 0.005,
 'log_dir': './logs_nn',
 'log_interval': 20,
 'loss_averaging_window': 100,
 'min_steps_to_checkpoint': 100,
 'num_restarts': 0,
 'num_training_steps': 2000,
 'num_validation_batches': 2,
 'optimizer': 'adam',
 'prediction_dir': './predictions_nn',
 'reader': <__main__.DataReader object at 0x2b09b639bef0>,
 'regularization_constant': 0.0,
 'warm_start_init_step': 0}
[[07/29/2023 06:10:07 PM]] all parameters:
[[07/29/2023 06:10:07 PM]] [('dense1/weights:0', [51, 64]),
 ('dense1/biases:0', [64]),
 ('dense2/weights:0', [115, 1]),
 ('dense2/biases:0', [1]),
 ('Variable:0', []),
 ('Variable_1:0', []),
 ('beta1_power:0', []),
 ('beta2_power:0', []),
 ('dense1/weights/Adam:0', [51, 64]),
 ('dense1/weights/Adam_1:0', [51, 64]),
 ('dense1/biases/Adam:0', [64]),
 ('dense1/biases/Adam_1:0', [64]),
 ('dense2/weights/Adam:0', [115, 1]),
 ('dense2/weights/Adam_1:0', [115, 1]),
 ('dense2/biases/Adam:0', [1]),
 ('dense2/biases/Adam_1:0', [1])]
[[07/29/2023 06:10:07 PM]] trainable parameters:
[[07/29/2023 06:10:07 PM]] [('dense1/weights:0', [51, 64]),
 ('dense1/biases:0', [64]),
 ('dense2/weights:0', [115, 1]),
 ('dense2/biases:0', [1])]
[[07/29/2023 06:10:07 PM]] trainable parameter count:
[[07/29/2023 06:10:07 PM]] 3444
[[07/29/2023 06:10:07 PM]] [[step        0]]     [[train]]     loss: 0.68319458       [[val]]     loss: 0.68883455       
[[07/29/2023 06:10:07 PM]] [[step       20]]     [[train]]     loss: 0.56979204       [[val]]     loss: 0.57618209       
[[07/29/2023 06:10:07 PM]] [[step       40]]     [[train]]     loss: 0.46623038       [[val]]     loss: 0.47686424       
[[07/29/2023 06:10:07 PM]] [[step       60]]     [[train]]     loss: 0.40111617       [[val]]     loss: 0.41881287       
[[07/29/2023 06:10:07 PM]] [[step       80]]     [[train]]     loss: 0.3646612        [[val]]     loss: 0.38707825       
[[07/29/2023 06:10:08 PM]] [[step      100]]     [[train]]     loss: 0.34012489       [[val]]     loss: 0.36397192       
[[07/29/2023 06:10:08 PM]] [[step      120]]     [[train]]     loss: 0.2766571        [[val]]     loss: 0.30839161       
[[07/29/2023 06:10:08 PM]] saving model to ./checkpoints_nn/model
[[07/29/2023 06:10:08 PM]] [[step      140]]     [[train]]     loss: 0.25599474       [[val]]     loss: 0.29219159       
[[07/29/2023 06:10:08 PM]] saving model to ./checkpoints_nn/model
[[07/29/2023 06:10:08 PM]] [[step      160]]     [[train]]     loss: 0.25222585       [[val]]     loss: 0.28899507       
[[07/29/2023 06:10:08 PM]] saving model to ./checkpoints_nn/model
[[07/29/2023 06:10:08 PM]] [[step      180]]     [[train]]     loss: 0.25620796       [[val]]     loss: 0.28761022       
[[07/29/2023 06:10:08 PM]] saving model to ./checkpoints_nn/model
[[07/29/2023 06:10:08 PM]] [[step      200]]     [[train]]     loss: 0.25417972       [[val]]     loss: 0.28944965       
[[07/29/2023 06:10:08 PM]] [[step      220]]     [[train]]     loss: 0.255205         [[val]]     loss: 0.28996068       
[[07/29/2023 06:10:08 PM]] [[step      240]]     [[train]]     loss: 0.25473716       [[val]]     loss: 0.29007148       
[[07/29/2023 06:10:08 PM]] [[step      260]]     [[train]]     loss: 0.25599814       [[val]]     loss: 0.29163568       
[[07/29/2023 06:10:08 PM]] [[step      280]]     [[train]]     loss: 0.25108748       [[val]]     loss: 0.29171031       
[[07/29/2023 06:10:08 PM]] [[step      300]]     [[train]]     loss: 0.25255159       [[val]]     loss: 0.29141249       
[[07/29/2023 06:10:08 PM]] [[step      320]]     [[train]]     loss: 0.25527406       [[val]]     loss: 0.29051898       
[[07/29/2023 06:10:08 PM]] [[step      340]]     [[train]]     loss: 0.25643006       [[val]]     loss: 0.28927746       
[[07/29/2023 06:10:08 PM]] [[step      360]]     [[train]]     loss: 0.25839927       [[val]]     loss: 0.28927773       
[[07/29/2023 06:10:08 PM]] [[step      380]]     [[train]]     loss: 0.25870618       [[val]]     loss: 0.29140517       
[[07/29/2023 06:10:08 PM]] [[step      400]]     [[train]]     loss: 0.256888         [[val]]     loss: 0.28945072       
[[07/29/2023 06:10:08 PM]] [[step      420]]     [[train]]     loss: 0.25346602       [[val]]     loss: 0.28835376       
[[07/29/2023 06:10:08 PM]] [[step      440]]     [[train]]     loss: 0.25472919       [[val]]     loss: 0.29000112       
[[07/29/2023 06:10:09 PM]] [[step      460]]     [[train]]     loss: 0.25222683       [[val]]     loss: 0.29075087       
[[07/29/2023 06:10:09 PM]] [[step      480]]     [[train]]     loss: 0.25575716       [[val]]     loss: 0.28997285       
[[07/29/2023 06:10:09 PM]] [[step      500]]     [[train]]     loss: 0.25868584       [[val]]     loss: 0.29029929       
[[07/29/2023 06:10:09 PM]] best validation loss of 0.287610222697258 at training step 180
[[07/29/2023 06:10:09 PM]] early stopping - ending training.
[[07/29/2023 06:10:09 PM]] restoring model parameters from ./checkpoints_nn/model-180
[[07/29/2023 06:10:09 PM]] saving order_ids with shape (279267,) to ./predictions_nn/order_ids.npy
[[07/29/2023 06:10:09 PM]] saving product_ids with shape (279267,) to ./predictions_nn/product_ids.npy
[[07/29/2023 06:10:09 PM]] saving predictions with shape (279267,) to ./predictions_nn/predictions.npy
[[07/29/2023 06:10:09 PM]] saving labels with shape (279267,) to ./predictions_nn/labels.npy
