[[07/30/2023 10:08:26 PM]] 
new run with parameters:
{'batch_size': 128,
 'checkpoint_dir': './checkpoints_nn',
 'early_stopping_steps': 300,
 'enable_parameter_averaging': False,
 'grad_clip': 5,
 'hidden_units': 64,
 'keep_prob_scalar': 1.0,
 'learning_rate': 0.005,
 'log_dir': './logs_nn',
 'log_interval': 20,
 'loss_averaging_window': 100,
 'min_steps_to_checkpoint': 100,
 'num_restarts': 0,
 'num_training_steps': 2000,
 'num_validation_batches': 2,
 'optimizer': 'adam',
 'prediction_dir': './predictions_nn',
 'reader': <__main__.DataReader object at 0x2b7730361c88>,
 'regularization_constant': 0.0,
 'warm_start_init_step': 0}
[[07/30/2023 10:08:46 PM]] all parameters:
[[07/30/2023 10:08:46 PM]] [('dense1/weights:0', [51, 64]),
 ('dense1/biases:0', [64]),
 ('dense2/weights:0', [115, 1]),
 ('dense2/biases:0', [1]),
 ('Variable:0', []),
 ('Variable_1:0', []),
 ('beta1_power:0', []),
 ('beta2_power:0', []),
 ('dense1/weights/Adam:0', [51, 64]),
 ('dense1/weights/Adam_1:0', [51, 64]),
 ('dense1/biases/Adam:0', [64]),
 ('dense1/biases/Adam_1:0', [64]),
 ('dense2/weights/Adam:0', [115, 1]),
 ('dense2/weights/Adam_1:0', [115, 1]),
 ('dense2/biases/Adam:0', [1]),
 ('dense2/biases/Adam_1:0', [1])]
[[07/30/2023 10:08:46 PM]] trainable parameters:
[[07/30/2023 10:08:46 PM]] [('dense1/weights:0', [51, 64]),
 ('dense1/biases:0', [64]),
 ('dense2/weights:0', [115, 1]),
 ('dense2/biases:0', [1])]
[[07/30/2023 10:08:46 PM]] trainable parameter count:
[[07/30/2023 10:08:46 PM]] 3444
[[07/30/2023 10:08:46 PM]] [[step        0]]     [[train]]     loss: 95324664.0       [[val]]     loss: 54236064.0       
[[07/30/2023 10:08:47 PM]] [[step       20]]     [[train]]     loss: -414000496.1904762     [[val]]     loss: -405934689.85714287     
[[07/30/2023 10:08:47 PM]] [[step       40]]     [[train]]     loss: -1044458548.7804879     [[val]]     loss: -1061191339.8780488     
[[07/30/2023 10:08:47 PM]] [[step       60]]     [[train]]     loss: -1881966442.819672     [[val]]     loss: -1890304929.6885245     
[[07/30/2023 10:08:47 PM]] [[step       80]]     [[train]]     loss: -3067676622.8641977     [[val]]     loss: -2986512616.382716     
[[07/30/2023 10:08:47 PM]] [[step      100]]     [[train]]     loss: -4381136799.8     [[val]]     loss: -4470815603.59     
[[07/30/2023 10:08:47 PM]] [[step      120]]     [[train]]     loss: -6765730197.12     [[val]]     loss: -6840129964.8     
[[07/30/2023 10:08:47 PM]] saving model to ./checkpoints_nn/model
[[07/30/2023 10:08:47 PM]] [[step      140]]     [[train]]     loss: -8927728916.48     [[val]]     loss: -8906654976.0     
[[07/30/2023 10:08:47 PM]] saving model to ./checkpoints_nn/model
[[07/30/2023 10:08:47 PM]] [[step      160]]     [[train]]     loss: -10606940456.96     [[val]]     loss: -10622408550.4     
[[07/30/2023 10:08:47 PM]] saving model to ./checkpoints_nn/model
[[07/30/2023 10:08:48 PM]] [[step      180]]     [[train]]     loss: -11686488939.52     [[val]]     loss: -11874192885.76     
[[07/30/2023 10:08:48 PM]] saving model to ./checkpoints_nn/model
[[07/30/2023 10:08:48 PM]] [[step      200]]     [[train]]     loss: -12080008263.68     [[val]]     loss: -12352357672.96     
[[07/30/2023 10:08:48 PM]] saving model to ./checkpoints_nn/model
[[07/30/2023 10:08:48 PM]] [[step      220]]     [[train]]     loss: -11821075937.28     [[val]]     loss: -12313621821.44     
[[07/30/2023 10:08:48 PM]] [[step      240]]     [[train]]     loss: -11728361681.92     [[val]]     loss: -12354184325.12     
[[07/30/2023 10:08:48 PM]] saving model to ./checkpoints_nn/model
[[07/30/2023 10:08:49 PM]] [[step      260]]     [[train]]     loss: -11792102773.76     [[val]]     loss: -12362876293.12     
[[07/30/2023 10:08:49 PM]] saving model to ./checkpoints_nn/model
[[07/30/2023 10:08:49 PM]] [[step      280]]     [[train]]     loss: -11844254556.16     [[val]]     loss: -12319416396.8     
[[07/30/2023 10:08:49 PM]] [[step      300]]     [[train]]     loss: -11994915328.0     [[val]]     loss: -12310724449.28     
[[07/30/2023 10:08:49 PM]] [[step      320]]     [[train]]     loss: -12209317201.92     [[val]]     loss: -12267264599.04     
[[07/30/2023 10:08:49 PM]] [[step      340]]     [[train]]     loss: -12325210065.92     [[val]]     loss: -12319416478.72     
[[07/30/2023 10:08:49 PM]] [[step      360]]     [[train]]     loss: -12244085002.24     [[val]]     loss: -12412130831.36     
[[07/30/2023 10:08:49 PM]] saving model to ./checkpoints_nn/model
[[07/30/2023 10:08:50 PM]] [[step      380]]     [[train]]     loss: -12105013509.12     [[val]]     loss: -12331005808.64     
[[07/30/2023 10:08:50 PM]] [[step      400]]     [[train]]     loss: -12186138511.36     [[val]]     loss: -12261469982.72     
[[07/30/2023 10:08:50 PM]] [[step      420]]     [[train]]     loss: -12470076119.04     [[val]]     loss: -12345492418.56     
[[07/30/2023 10:08:50 PM]] [[step      440]]     [[train]]     loss: -12435308277.76     [[val]]     loss: -12383157596.16     
[[07/30/2023 10:08:50 PM]] [[step      460]]     [[train]]     loss: -12516433320.96     [[val]]     loss: -12351287009.28     
[[07/30/2023 10:08:50 PM]] [[step      480]]     [[train]]     loss: -12661299466.24     [[val]]     loss: -12406336092.16     
[[07/30/2023 10:08:50 PM]] [[step      500]]     [[train]]     loss: -12423719014.4     [[val]]     loss: -12412130785.28     
[[07/30/2023 10:08:50 PM]] [[step      520]]     [[train]]     loss: -12197727861.76     [[val]]     loss: -12368670945.28     
[[07/30/2023 10:08:50 PM]] [[step      540]]     [[train]]     loss: -12018093875.2     [[val]]     loss: -12232496773.12     
[[07/30/2023 10:08:50 PM]] [[step      560]]     [[train]]     loss: -11977531407.36     [[val]]     loss: -12209318179.84     
[[07/30/2023 10:08:50 PM]] [[step      580]]     [[train]]     loss: -11983326069.76     [[val]]     loss: -12252778050.56     
[[07/30/2023 10:08:50 PM]] [[step      600]]     [[train]]     loss: -12041272570.88     [[val]]     loss: -12264367344.64     
[[07/30/2023 10:08:51 PM]] [[step      620]]     [[train]]     loss: -12041272545.28     [[val]]     loss: -12310724469.76     
[[07/30/2023 10:08:51 PM]] [[step      640]]     [[train]]     loss: -12220906536.96     [[val]]     loss: -12452693304.32     
[[07/30/2023 10:08:51 PM]] saving model to ./checkpoints_nn/model
[[07/30/2023 10:08:51 PM]] [[step      660]]     [[train]]     loss: -12186138634.24     [[val]]     loss: -12310724515.84     
[[07/30/2023 10:08:51 PM]] [[step      680]]     [[train]]     loss: -11983326054.4     [[val]]     loss: -12267264655.36     
[[07/30/2023 10:08:51 PM]] [[step      700]]     [[train]]     loss: -12232495759.36     [[val]]     loss: -12177447608.32     
[[07/30/2023 10:08:51 PM]] [[step      720]]     [[train]]     loss: -12116602854.4     [[val]]     loss: -12226702161.92     
[[07/30/2023 10:08:51 PM]] [[step      740]]     [[train]]     loss: -12047067074.56     [[val]]     loss: -12151371755.52     
[[07/30/2023 10:08:51 PM]] [[step      760]]     [[train]]     loss: -11919584885.76     [[val]]     loss: -12255675356.16     
[[07/30/2023 10:08:51 PM]] [[step      780]]     [[train]]     loss: -11971736693.76     [[val]]     loss: -12238291420.16     
[[07/30/2023 10:08:51 PM]] [[step      800]]     [[train]]     loss: -11867433088.0     [[val]]     loss: -12391849569.28     
[[07/30/2023 10:08:52 PM]] [[step      820]]     [[train]]     loss: -12023888537.6     [[val]]     loss: -12220907484.16     
[[07/30/2023 10:08:52 PM]] [[step      840]]     [[train]]     loss: -12226701153.28     [[val]]     loss: -12241188736.0     
[[07/30/2023 10:08:52 PM]] [[step      860]]     [[train]]     loss: -12452692275.2     [[val]]     loss: -12333903093.76     
[[07/30/2023 10:08:52 PM]] [[step      880]]     [[train]]     loss: -12672888780.8     [[val]]     loss: -12391849605.12     
[[07/30/2023 10:08:52 PM]] [[step      900]]     [[train]]     loss: -12690272716.8     [[val]]     loss: -12423720192.0     
[[07/30/2023 10:08:52 PM]] [[step      920]]     [[train]]     loss: -12672888775.68     [[val]]     loss: -12426617487.36     
[[07/30/2023 10:08:52 PM]] [[step      940]]     [[train]]     loss: -12441102940.16     [[val]]     loss: -12394746931.2     
[[07/30/2023 10:08:52 PM]] [[step      960]]     [[train]]     loss: -12412129730.56     [[val]]     loss: -12359979069.44     
[[07/30/2023 10:08:52 PM]] best validation loss of -12452693304.32 at training step 640
[[07/30/2023 10:08:52 PM]] early stopping - ending training.
[[07/30/2023 10:08:52 PM]] restoring model parameters from ./checkpoints_nn/model-640
[[07/30/2023 10:08:53 PM]] saving order_ids with shape (248126,) to ./predictions_nn/order_ids.npy
[[07/30/2023 10:08:53 PM]] saving product_ids with shape (248126,) to ./predictions_nn/product_ids.npy
[[07/30/2023 10:08:53 PM]] saving predictions with shape (248126,) to ./predictions_nn/predictions.npy
[[07/30/2023 10:08:53 PM]] saving labels with shape (248126,) to ./predictions_nn/labels.npy
