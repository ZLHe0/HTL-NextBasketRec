[[07/31/2023 03:09:19 PM]] 
new run with parameters:
{'batch_size': 128,
 'checkpoint_dir': './checkpoints_nn',
 'early_stopping_steps': 300,
 'enable_parameter_averaging': False,
 'grad_clip': 5,
 'hidden_units': 64,
 'keep_prob_scalar': 1.0,
 'learning_rate': 0.005,
 'log_dir': './logs_nn',
 'log_interval': 20,
 'loss_averaging_window': 100,
 'min_steps_to_checkpoint': 100,
 'num_restarts': 0,
 'num_training_steps': 2000,
 'num_validation_batches': 2,
 'optimizer': 'adam',
 'prediction_dir': './predictions_nn',
 'reader': <__main__.DataReader object at 0x2b96e8325d30>,
 'regularization_constant': 0.0,
 'warm_start_init_step': 0}
[[07/31/2023 03:09:33 PM]] all parameters:
[[07/31/2023 03:09:33 PM]] [('dense1/weights:0', [51, 64]),
 ('dense1/biases:0', [64]),
 ('dense2/weights:0', [115, 1]),
 ('dense2/biases:0', [1]),
 ('Variable:0', []),
 ('Variable_1:0', []),
 ('beta1_power:0', []),
 ('beta2_power:0', []),
 ('dense1/weights/Adam:0', [51, 64]),
 ('dense1/weights/Adam_1:0', [51, 64]),
 ('dense1/biases/Adam:0', [64]),
 ('dense1/biases/Adam_1:0', [64]),
 ('dense2/weights/Adam:0', [115, 1]),
 ('dense2/weights/Adam_1:0', [115, 1]),
 ('dense2/biases/Adam:0', [1]),
 ('dense2/biases/Adam_1:0', [1])]
[[07/31/2023 03:09:33 PM]] trainable parameters:
[[07/31/2023 03:09:33 PM]] [('dense1/weights:0', [51, 64]),
 ('dense1/biases:0', [64]),
 ('dense2/weights:0', [115, 1]),
 ('dense2/biases:0', [1])]
[[07/31/2023 03:09:33 PM]] trainable parameter count:
[[07/31/2023 03:09:33 PM]] 3444
[[07/31/2023 03:09:33 PM]] [[step        0]]     [[train]]     loss: 0.71553606       [[val]]     loss: 0.71783453       
[[07/31/2023 03:09:33 PM]] [[step       20]]     [[train]]     loss: 0.47210177       [[val]]     loss: 0.45547202       
[[07/31/2023 03:09:34 PM]] [[step       40]]     [[train]]     loss: 0.39852457       [[val]]     loss: 0.39204978       
[[07/31/2023 03:09:34 PM]] [[step       60]]     [[train]]     loss: 0.36847977       [[val]]     loss: 0.3641972        
[[07/31/2023 03:09:34 PM]] [[step       80]]     [[train]]     loss: 0.36041863       [[val]]     loss: 0.3500667        
[[07/31/2023 03:09:34 PM]] [[step      100]]     [[train]]     loss: 0.34568849       [[val]]     loss: 0.34174616       
[[07/31/2023 03:09:34 PM]] [[step      120]]     [[train]]     loss: 0.31840305       [[val]]     loss: 0.31601826       
[[07/31/2023 03:09:34 PM]] saving model to ./checkpoints_nn/model
[[07/31/2023 03:09:34 PM]] [[step      140]]     [[train]]     loss: 0.31833759       [[val]]     loss: 0.31237386       
[[07/31/2023 03:09:34 PM]] saving model to ./checkpoints_nn/model
[[07/31/2023 03:09:34 PM]] [[step      160]]     [[train]]     loss: 0.31753815       [[val]]     loss: 0.31317821       
[[07/31/2023 03:09:34 PM]] [[step      180]]     [[train]]     loss: 0.31124286       [[val]]     loss: 0.31165862       
[[07/31/2023 03:09:34 PM]] saving model to ./checkpoints_nn/model
[[07/31/2023 03:09:34 PM]] [[step      200]]     [[train]]     loss: 0.3127608        [[val]]     loss: 0.30698765       
[[07/31/2023 03:09:34 PM]] saving model to ./checkpoints_nn/model
[[07/31/2023 03:09:34 PM]] [[step      220]]     [[train]]     loss: 0.30617961       [[val]]     loss: 0.30712957       
[[07/31/2023 03:09:34 PM]] [[step      240]]     [[train]]     loss: 0.30549489       [[val]]     loss: 0.30598766       
[[07/31/2023 03:09:34 PM]] saving model to ./checkpoints_nn/model
[[07/31/2023 03:09:34 PM]] [[step      260]]     [[train]]     loss: 0.30627573       [[val]]     loss: 0.30269798       
[[07/31/2023 03:09:34 PM]] saving model to ./checkpoints_nn/model
[[07/31/2023 03:09:35 PM]] [[step      280]]     [[train]]     loss: 0.30442313       [[val]]     loss: 0.30722903       
[[07/31/2023 03:09:35 PM]] [[step      300]]     [[train]]     loss: 0.30362784       [[val]]     loss: 0.30716416       
[[07/31/2023 03:09:35 PM]] [[step      320]]     [[train]]     loss: 0.30878401       [[val]]     loss: 0.30646893       
[[07/31/2023 03:09:35 PM]] [[step      340]]     [[train]]     loss: 0.30451225       [[val]]     loss: 0.30498831       
[[07/31/2023 03:09:35 PM]] [[step      360]]     [[train]]     loss: 0.30822451       [[val]]     loss: 0.30820192       
[[07/31/2023 03:09:35 PM]] [[step      380]]     [[train]]     loss: 0.31139066       [[val]]     loss: 0.30404323       
[[07/31/2023 03:09:35 PM]] [[step      400]]     [[train]]     loss: 0.31034525       [[val]]     loss: 0.30473097       
[[07/31/2023 03:09:35 PM]] [[step      420]]     [[train]]     loss: 0.31398765       [[val]]     loss: 0.30537142       
[[07/31/2023 03:09:35 PM]] [[step      440]]     [[train]]     loss: 0.31768239       [[val]]     loss: 0.30574809       
[[07/31/2023 03:09:35 PM]] [[step      460]]     [[train]]     loss: 0.3138547        [[val]]     loss: 0.30373922       
[[07/31/2023 03:09:35 PM]] [[step      480]]     [[train]]     loss: 0.31392748       [[val]]     loss: 0.30528864       
[[07/31/2023 03:09:35 PM]] [[step      500]]     [[train]]     loss: 0.31467247       [[val]]     loss: 0.30165105       
[[07/31/2023 03:09:35 PM]] saving model to ./checkpoints_nn/model
[[07/31/2023 03:09:35 PM]] [[step      520]]     [[train]]     loss: 0.31520265       [[val]]     loss: 0.30067621       
[[07/31/2023 03:09:35 PM]] saving model to ./checkpoints_nn/model
[[07/31/2023 03:09:36 PM]] [[step      540]]     [[train]]     loss: 0.31356921       [[val]]     loss: 0.30465532       
[[07/31/2023 03:09:36 PM]] [[step      560]]     [[train]]     loss: 0.31801197       [[val]]     loss: 0.30492068       
[[07/31/2023 03:09:36 PM]] [[step      580]]     [[train]]     loss: 0.31740052       [[val]]     loss: 0.3049808        
[[07/31/2023 03:09:36 PM]] [[step      600]]     [[train]]     loss: 0.31745435       [[val]]     loss: 0.30892073       
[[07/31/2023 03:09:36 PM]] [[step      620]]     [[train]]     loss: 0.30974266       [[val]]     loss: 0.307693         
[[07/31/2023 03:09:36 PM]] [[step      640]]     [[train]]     loss: 0.31652167       [[val]]     loss: 0.30506674       
[[07/31/2023 03:09:36 PM]] [[step      660]]     [[train]]     loss: 0.31514196       [[val]]     loss: 0.3060677        
[[07/31/2023 03:09:36 PM]] [[step      680]]     [[train]]     loss: 0.3121273        [[val]]     loss: 0.30643243       
[[07/31/2023 03:09:36 PM]] [[step      700]]     [[train]]     loss: 0.31633          [[val]]     loss: 0.30631646       
[[07/31/2023 03:09:36 PM]] [[step      720]]     [[train]]     loss: 0.31590711       [[val]]     loss: 0.30621241       
[[07/31/2023 03:09:36 PM]] [[step      740]]     [[train]]     loss: 0.30936003       [[val]]     loss: 0.30549959       
[[07/31/2023 03:09:36 PM]] [[step      760]]     [[train]]     loss: 0.30914082       [[val]]     loss: 0.30393578       
[[07/31/2023 03:09:36 PM]] [[step      780]]     [[train]]     loss: 0.31248957       [[val]]     loss: 0.30391474       
[[07/31/2023 03:09:36 PM]] [[step      800]]     [[train]]     loss: 0.3062479        [[val]]     loss: 0.3053353        
[[07/31/2023 03:09:36 PM]] [[step      820]]     [[train]]     loss: 0.30981738       [[val]]     loss: 0.30476577       
[[07/31/2023 03:09:36 PM]] [[step      840]]     [[train]]     loss: 0.31258817       [[val]]     loss: 0.30693269       
[[07/31/2023 03:09:36 PM]] best validation loss of 0.3006762075424194 at training step 520
[[07/31/2023 03:09:36 PM]] early stopping - ending training.
[[07/31/2023 03:09:36 PM]] restoring model parameters from ./checkpoints_nn/model-520
[[07/31/2023 03:09:37 PM]] saving order_ids with shape (252278,) to ./predictions_nn/order_ids.npy
[[07/31/2023 03:09:37 PM]] saving product_ids with shape (252278,) to ./predictions_nn/product_ids.npy
[[07/31/2023 03:09:37 PM]] saving predictions with shape (252278,) to ./predictions_nn/predictions.npy
[[07/31/2023 03:09:37 PM]] saving labels with shape (252278,) to ./predictions_nn/labels.npy
